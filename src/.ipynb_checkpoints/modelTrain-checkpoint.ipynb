{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataFolder=\"../RAVEN/Trial\"\n",
    "datafiles=[dataFolder+\"/\"+x for x in os.listdir(dataFolder)]\n",
    "myData=pd.DataFrame()\n",
    "\n",
    "#getting all info into one file\n",
    "#mapping wrong question to 0\n",
    "#mapping right question to 1\n",
    "for file in datafiles:\n",
    "    xlsxfile=pd.ExcelFile(file)\n",
    "    sheets = {sheet_name: xlsxfile.parse(sheet_name) for sheet_name in xlsxfile.sheet_names}\n",
    "    if file.split(\"_\")[-1].split(\".\")[0]==\"Right\":\n",
    "        answer=1\n",
    "    else:\n",
    "        answer=0\n",
    "    for sheet in sheets:\n",
    "        if not sheets[sheet].empty:\n",
    "            subjects=sheets[sheet][\"Unnamed: 22\"]\n",
    "            del sheets[sheet][\"Unnamed: 22\"]\n",
    "            subjects=subjects.str.startswith(\"DEI\")\n",
    "            subjects=subjects.astype(int)\n",
    "            sheets[sheet][\"Answer\"]=answer\n",
    "            sheets[sheet][\"Area\"]=subjects\n",
    "            myData=pd.concat([myData,sheets[sheet]], ignore_index=True)\n",
    "\n",
    "#centering and normalizing data\n",
    "for col in myData:\n",
    "    if col != \"Answer\" and col != \"Area\":\n",
    "        myData[col]=(myData[col]-myData[col].mean())/myData[col].std()\n",
    "for col in myData:\n",
    "    if col != \"Answer\" and col != \"Area\":\n",
    "        myData[col]=myData[col][~((myData[col]-myData[col].mean()).abs() > 3*myData[col].std())]\n",
    "        \n",
    "myData=myData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(myData, alpha=0.2, figsize=(len(myData.columns), len(myData.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Division\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_set, test_set = train_test_split(myData, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_train = training_set.iloc[:,0:-2].values\n",
    "Y_train = training_set.iloc[:,-1].values\n",
    "X_test = test_set.iloc[:,0:-2].values\n",
    "Y_test = test_set.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Support Vector Machine Classifier: 55.19287833827893%\n",
      "F1-Score for Support Vector Machine Classifier: 70.45009784735812%\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clrSVM = SVC(kernel='sigmoid', random_state = 1, gamma=\"auto\")\n",
    "clrSVM.fit(X_train,Y_train)\n",
    "\n",
    "predSVM = clrSVM.predict(X_test)\n",
    "\n",
    "#cmSVM = confusion_matrix(Y_test,predictions)\n",
    "print(\"Accuracy for Support Vector Machine Classifier: \" + str(accuracy_score(Y_test, predSVM)*100)+\"%\")\n",
    "print(\"F1-Score for Support Vector Machine Classifier: \" + str(f1_score(Y_test, predSVM)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Neural Network Classifier: 56.97329376854599%\n",
      "F1-Score for Neural Network Classifier: 69.2144373673036%\n"
     ]
    }
   ],
   "source": [
    "#NN\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_trainNN = scaler.transform(X_train)\n",
    "X_testNN = scaler.transform(X_test)\n",
    "\n",
    "clrMLP = MLPClassifier(hidden_layer_sizes=(10,5),max_iter=900,activation=\"identity\",solver=\"lbfgs\")\n",
    "clrMLP.fit(X_trainNN,Y_train)\n",
    "\n",
    "predNN = clrMLP.predict(X_test)\n",
    "\n",
    "#cmNN = confusion_matrix(Y_test,predictions)\n",
    "print(\"Accuracy for Neural Network Classifier: \" + str(accuracy_score(Y_test, predNN)*100)+\"%\")\n",
    "print(\"F1-Score for Neural Network Classifier: \" + str(f1_score(Y_test, predNN)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree Classifier: 58.160237388724035%\n",
      "F1-Score for Decision Tree Classifier: 62.40000000000001%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clrDT = DecisionTreeClassifier(criterion=\"gini\")\n",
    "clrDT = clrDT.fit(X_train, Y_train)\n",
    "\n",
    "predDT = clrDT.predict(X_test)\n",
    "\n",
    "#cmDT = confusion_matrix(Y_test,predictions)\n",
    "print(\"Accuracy for Decision Tree Classifier: \" + str(accuracy_score(Y_test, predDT)*100)+\"%\")\n",
    "print(\"F1-Score for Decision Tree Classifier: \" + str(f1_score(Y_test, predDT)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forrest Classifier: 56.676557863501486%\n",
      "F1-Score for Random FOrrest Classifier: 63.13131313131313%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clrRF = RandomForestClassifier(n_estimators=15)\n",
    "clrRF = clrRF.fit(X_train, Y_train)\n",
    "\n",
    "predRF = clrRF.predict(X_test)\n",
    "\n",
    "#cmRF = confusion_matrix(Y_test,predictions)\n",
    "print(\"Accuracy for Random Forrest Classifier: \" + str(accuracy_score(Y_test, predRF)*100)+\"%\")\n",
    "print(\"F1-Score for Random FOrrest Classifier: \" + str(f1_score(Y_test, predRF)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNeighbors Classifier: 52.52225519287834%\n",
      "F1-Score for KNeighbors Classifier: 59.59595959595959%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clrKN = KNeighborsClassifier(n_neighbors=3)\n",
    "clrKN = clrKN.fit(X_train, Y_train)\n",
    "\n",
    "predKN = clrKN.predict(X_test)\n",
    "\n",
    "#cmKN = confusion_matrix(Y_test,predictions)\n",
    "print(\"Accuracy for KNeighbors Classifier: \" + str(accuracy_score(Y_test, predKN)*100)+\"%\") \n",
    "print(\"F1-Score for KNeighbors Classifier: \" + str(f1_score(Y_test, predKN)*100)+\"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
